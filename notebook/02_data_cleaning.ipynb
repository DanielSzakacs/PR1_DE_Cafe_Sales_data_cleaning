{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replacing invalid string values\n",
    "\n",
    "Some columns contain incorrect placeholders for missing data, such as `\"error\"`, `\"unknown\"`, or `\"nan\"`.  \n",
    "These should be consistently replaced with proper `NaN` values for accurate analysis and type conversion.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"../data/raw/dirty_cafe_sales.csv\")\n",
    "\n",
    "\n",
    "# Create function to replace the incorrect missing indicators\n",
    "def clean_incorrect_missing_indicators(columns: list[str], df: pd.DataFrame = df):\n",
    "    \"\"\"\n",
    "        Replaces string-based placeholders for missing values (e.g., \"error\", \"unknown\", \"nan\") \n",
    "        with actual NumPy NaN values in the specified columns.\n",
    "\n",
    "        Parameters:\n",
    "            columns (list[str]): List of column names to apply the cleaning on.\n",
    "            df (pd.DataFrame): The input DataFrame (default is `df`).\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: A new DataFrame with cleaned missing value indicators.\n",
    "    \"\"\"\n",
    "\n",
    "    df_copy = df.copy()\n",
    "    string_to_replace = [\"error\", \"nan\", \"unknown\"]\n",
    "    for col in columns:\n",
    "        if col in df.columns:\n",
    "            def clean_value(x):\n",
    "                if isinstance(x, str):\n",
    "                    lower_x = x.strip().lower()\n",
    "                    if lower_x in string_to_replace:\n",
    "                        return np.nan\n",
    "                return x\n",
    "            df_copy[col] = df_copy[col].apply(clean_value)\n",
    "    return df_copy    \n",
    "\n",
    "# Call the function\n",
    "df = clean_incorrect_missing_indicators(columns=df.columns.to_list(), df=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Takeaway', 'In-store', nan], dtype=object)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Location\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert feature data types\n",
    "\n",
    "We will convert numerical and date columns to appropriate types using `pd.to_numeric` and `pd.to_datetime`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   Transaction ID    10000 non-null  object        \n",
      " 1   Item              9031 non-null   object        \n",
      " 2   Quantity          9521 non-null   float64       \n",
      " 3   Price Per Unit    9467 non-null   float64       \n",
      " 4   Total Spent       9498 non-null   float64       \n",
      " 5   Payment Method    6822 non-null   object        \n",
      " 6   Location          6039 non-null   object        \n",
      " 7   Transaction Date  9540 non-null   datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(3), object(4)\n",
      "memory usage: 625.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Lets turn numerical features to int\n",
    "for col in ['Price Per Unit', 'Total Spent', 'Quantity']:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "df['Transaction Date'] = pd.to_datetime(df['Transaction Date'])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Location            39.61\n",
       "Payment Method      31.78\n",
       "Item                 9.69\n",
       "Price Per Unit       5.33\n",
       "Total Spent          5.02\n",
       "Quantity             4.79\n",
       "Transaction Date     4.60\n",
       "Transaction ID       0.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the missing values\n",
    "(df.isna().sum() / len(df) * 100).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The first two features have more than 30% missing values. We need to impute them.  \n",
    "#### Let's check the distribution of available values to decide how to fill the missing entries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Payment Method\n",
      "Digital Wallet    0.335825\n",
      "Credit Card       0.333187\n",
      "Cash              0.330988\n",
      "Name: proportion, dtype: float64\n",
      "Location\n",
      "Takeaway    0.500414\n",
      "In-store    0.499586\n",
      "Name: proportion, dtype: float64\n",
      "Item\n",
      "Juice       0.129664\n",
      "Coffee      0.129000\n",
      "Salad       0.127118\n",
      "Cake        0.126121\n",
      "Sandwich    0.125235\n",
      "Smoothie    0.121360\n",
      "Cookie      0.120917\n",
      "Tea         0.120585\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Lets check the ration of the avaliable values \n",
    "for col in [\n",
    "       'Payment Method', 'Location', 'Item']:\n",
    "    print(df[col].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Based on the ration of the 'Payment Method', 'Item' and 'Location' we will fill the missing values by proportion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proportional_fill(df: pd.DataFrame, column: str):\n",
    "    \"\"\"\n",
    "        Fill nan values of the column based on the avaliable valuables ratio\n",
    "\n",
    "        Props:\n",
    "            df: pd.DataFrame\n",
    "            column: str - name of thh dataframe feature\n",
    "\n",
    "        Return: \n",
    "            df: pd.DataFrame - with the filled missing values\n",
    "    \"\"\"\n",
    "    propbs = df[column].value_counts(normalize=True)\n",
    "    n_missing = df[column].isna().sum()\n",
    "\n",
    "    input_values = np.random.choice(propbs.index, size=n_missing, p=propbs.values)\n",
    "    df.loc[df[column].isna(), column] = input_values\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fill out missing values\n",
    "* Object types will be filled based on there avaliable values proportion\n",
    "* Numerical values by there median\n",
    "* DateTime features will be droped as there is not data based we know when it happaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = proportional_fill(df, 'Location')\n",
    "df = proportional_fill(df, 'Payment Method')\n",
    "df = proportional_fill(df, 'Item')\n",
    "\n",
    "# Numerical values will be filled out with there median\n",
    "df['Price Per Unit'] = df['Price Per Unit'].fillna(df['Price Per Unit'].median()) \n",
    "df['Total Spent'] = df['Total Spent'].fillna(df['Total Spent'].median()) \n",
    "df['Quantity'] = df['Quantity'].fillna(df['Quantity'].median()) \n",
    "\n",
    "# Drop DateTime\n",
    "df = df.dropna(subset=[\"Transaction Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transaction ID      0.0\n",
       "Item                0.0\n",
       "Quantity            0.0\n",
       "Price Per Unit      0.0\n",
       "Total Spent         0.0\n",
       "Payment Method      0.0\n",
       "Location            0.0\n",
       "Transaction Date    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets check if is there any missing values\n",
    "(df.isna().sum() / len(df) * 100).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
